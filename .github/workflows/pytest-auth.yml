---
# This workflow is meant as a foundational workflow for running integration/unit tests on multiple targeted
# ubuntu versions with multiple python versions.
#
# This workflow utilizes the build-dependency-cache workflow which sets up the environment dependencies using
# bootstrap.py --all
#

# Documentation for the syntax of this file is located
# https://docs.github.com/en/free-pro-team@latest/actions/reference/workflow-syntax-for-github-actions

# The workflow name will show up in the action tab on github during execution
# https://github.com/VOLTTRON/volttron/actions (or if you are pushing to your own fork change the user)
name: Testing platform auth

# Determine what events are going to trigger a running of the workflow
on: [push, pull_request]

jobs:
  # The job named build
  build:
    # The strategy allows customization of the build and allows matrixing the version of os and software
    # https://docs.github.com/en/free-pro-team@l.atest/actions/reference/workflow-syntax-for-github-actions#jobsjob_idstrategy
    strategy:
      fail-fast: false
      matrix:
        # Each entry in the os and python-version matrix will be run so for the 3 x 4 there will be 12 jobs run
        os: [ ubuntu-16.04, ubuntu-18.04, ubuntu-20.04 ]
        python-version: [ 3.6, 3.7] # , 3.8, 3.9 ]

    # Run-on determines the operating system available to run on
    # - At the current time there is only ubuntu machines between 16.04 and 20.04 available
    # - This uses the matrix os from the strategy above
    runs-on: ${{ matrix.os }}

    # Each step will be run in order of listing.
    steps:
      # checkout the volttron repository and set current direectory to it
      - uses: actions/checkout@v2

      # setup the python environment for the operating system
      - name: Set up Python ${{matrix.os}} ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      # Attempt to restore the cache from the build-dependency-cache workflow if present then
      # the output value steps.check_files.outputs.files_exists will be set (see the next step for usage)
      - name: Has restored cache
        id: check_files
        uses: andstor/file-existence-action@v1
        with:
          files: "env/bin/activate"

      # This step is only run if the cache wasn't able to be restored.
      - name: Install dependencies
        if: steps.check_files.outputs.files_exists != 'true'
        run: |
          pip install wheel
          python bootstrap.py --all  --force

      - name: Install volttron
        run: |
          source env/bin/activate
          pip install -e .

      # Run the specified tests and save the results to a unique file that can be archived for later analysis.
      - name: Run pytest
        run: |
          source env/bin/activate
          pip install -e .
          pytest volttrontesting/platform/auth_tests -rf -o junit_family=xunit2 --junitxml=output/test-auth-${{matrix.os}}-${{ matrix.python-version }}-results.xml

      # Archive the results from the pytest to storage.
      - name: Archive test results
        uses: actions/upload-artifact@v2
        if: always()
        with:
          name: pytest-report
          path: output/test-auth-${{matrix.os}}-${{ matrix.python-version }}-results.xml
    
#       - name: Publish Unit Test Results
#         uses: EnricoMi/publish-unit-test-result-action@v1.5
#         if: always()
#         with:
#           github_token: ${{ secrets.WORKFLOW_ACCESS_TOKEN }}
#           files: output/test-testutils*.xml
          
          
#-cov=com --cov-report=xml --cov-report=html
# pytest tests.py --doctest-modules --junitxml=junit/test-results.xml --cov=com --cov-report=xml --cov-report=html
#    - name: Lint with flake8
#      run: |
#        # stop the build if there are Python syntax errors or undefined names
#        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
#        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
#        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
#    - name: Test with pytest
#      run: |
#        pytest --junitxml=junit/test-results.xml --cov=com --cov-report=xml --cov-report=html
